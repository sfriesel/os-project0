			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Stefan Friesel <sfriesel@zedat.fu-berlin.de>

---- PRELIMINARIES ----

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
in timer.c:
+static struct list sleeping_list;
List of processes blocked to be waked up after timeout.

+struct sleep_semaphore
+{
+  struct semaphore sema;
+  int64_t wakeup_time;
+  struct list_elem elem;
+};
Struct for bookkeeping of threads in sleeping_list. Upping the semaphore
wakes the corresponding thread.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.
The running thread creates a struct sleep_semaphore for itself and adds it
to the sleeping list atomically. It then waits on the semaphore, which gets
released after wakeup_time is reached by a service routine called from
timer_interrupt().

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
The list of sleeping threads is sorted by earliest wakeup-time, so that on
each timer_interrupt only the front of the list needs to be checked.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
By disabling interrupts while editing sleeping_list

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
By disabling interrupts while editing sleeping_list

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
The design keeps timer operation seperate from threading as much as possible.
Another possibility would have been to add a wakeup field directly in struct
thread and work directly with the threads at the cost of modularization.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
Instead of one ready list, we need 64 (PRI_COUNT = PRI_MAX - PRI_MIN + 1)
in thread.c:
+static struct list ready_lists[PRI_COUNT];

A list of all locks the thread actively holds (used for priority donation)
in thread.h (struct thread):
+   struct list held_locks;


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
Each thread has a list of all locks it currently holds. By looking at the
lock->waiters list of each held lock it knows all the threads it currently
receives donations from (and, by recursion, the donators of its donators etc.).

+---thread---+
| held_locks |--->+---lock---+
|  priority  |    | waiters  |-->+---thread---+
+------------+    +----------+   | held_locks |--->+---lock---+
                                 |  priority  |    | waiters  |-->+---thread---+
                                 +------------+    +----------+   | held_locks |
                                                                  |  priority  |
                                                                  +------------+

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
By searching the respective waiter list for the thread with highest priority
instead of waking up the first in the list.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
The running thread notices, that the lock is currently held and calls
thread_on_donation_update() on the holding thread. This causes the holding
thread to recalculate its effective priority and possibly reschedule itself. By
getting the _effective_ priority of donating threads, recursive donation is
possible.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
The lock is removed from the thread's lock list. The semaphore associated
with the lock is upped and hence the highest priority waiting thread scheduled if it has
a higher priority than the running thread.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
If the thread is rescheduled directly in response to the priority change a race
condition might cause the thread to end up in the wrong ready queue. My
implementation only allows changing the running threads priority, so this race
cannot happen. A lock for accesing the ready queues could be used to avoid the
race.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
While adding a lock list to struct thread mixes threading and synchronization
primitives, it allows for easy priority inheritance (especially recursive),
because the threads a re directly reachable from all primitives without adding
new data structures. It would have been possible to keep seperate lists about
which threads are waiting on which semaphore, but it would require more code and
incur additional overhead.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in lib/fixed_point.h:
A fixed point type represented as a multiple of 2^(-14)
+typedef struct fp
+{
+  int32_t v;
+} fp_t;

in thread.c:
+static fp_t load_avg = { 0 };

in thread.h (struct thread):
+    int nice;                           /* Niceness */
+    fp_t recent_cpu;                    /* time weighted recent cpu usage */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   1   2  63  60  58        A
 4      4   1   2  62  60  58        A
 8      8   1   2  61  60  58        A
12     12   1   2  60  60  58        B
16     12   5   2  60  59  58        A
20     16   5   2  59  59  58        B
24     16   9   2  59  58  58        A
28     20   9   2  58  58  58        C
32     20   9   6  58  58  57        B
36     20   13  6  58  57  57        A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
It is not specified in which order threads of the same priority get scheduled.
Assumed round robin.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
Interrupt contexts are only used for recalculating average load and priorities
once per second. The most expensive operation is probably determining the
effective priority of threads with complex priority inheritance, which could be
bad for performance in certain scenarios.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
The implementation is very close to the specification. The only major
design decision being the use of an ADT for fixed point arithmetic.
In some places disabling interrupts might be replaceable by locks.


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
I used an abstract data type to improve readability of formulas.
